{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHAPTER 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/nyc-parking-violations-2020.csv\"\n",
    "df = pd.read_csv(path, usecols=[\n",
    "    \"Plate ID\", \"Registration State\", \"Vehicle Make\", \"Vehicle Color\", \n",
    "    \"Violation Time\", \"Street Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.72 s ± 11.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "total = len(df.index)\n",
    "without_any_nans = len(df.dropna().index)\n",
    "(total - without_any_nans) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.87 s ± 15.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# loss with subset features\n",
    "subset = [\"Plate ID\", \"Registration State\", \"Vehicle Make\", \"Street Name\"]\n",
    "(len(df) - len(df.dropna(subset=subset))) * 100\n",
    "\n",
    "subset = [\"Plate ID\", \"Registration State\", \"Street Name\"]\n",
    "(len(df.index) - len(df.dropna(subset=subset).index)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32 s ± 13.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# How many rows would you eliminate if you required at least three non-null \n",
    "# values from the four columns Plate ID, Registration State, Vehicle Make, and\n",
    "# Street Name\n",
    "\n",
    "rows_with_at_least_3_non_nans = len(\n",
    "    df[\n",
    "        (\n",
    "            df['Plate ID'].notnull().astype(int) + \n",
    "            df['Registration State'].notnull().astype(int) + \n",
    "            df['Vehicle Make'].notnull().astype(int) + \n",
    "            df['Street Name'].notnull().astype(int)\n",
    "        ) >= 3\n",
    "    ]\n",
    ")\n",
    "total - rows_with_at_least_3_non_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41 s ± 15.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Which of the columns you've imported has the greatest number of NaN values\n",
    "df.isnull().astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.92 s ± 16.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Null data is bad, but there is plenty of bad non-null data, too. For example,\n",
    "# many cars with BLANKPLATE as a plate ID were ticketed. Turn these into NaN \n",
    "# values, and rerun the previous query.\n",
    "\n",
    "df['Plate ID'] = df['Plate ID'].replace('BLANKPLATE', pd.NA)\n",
    "df.isnull().astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/nyc-parking-violations-2020.csv\"\n",
    "df = pl.read_csv(path, columns=[\n",
    "    \"Plate ID\", \"Registration State\", \"Vehicle Make\", \"Vehicle Color\", \n",
    "    \"Violation Time\", \"Street Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.8 ms ± 709 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "total = len(df)\n",
    "without_any_nans = len(df.drop_nulls())\n",
    "(total - without_any_nans) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 ms ± 2.32 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# loss with subset features\n",
    "subset = [\"Plate ID\", \"Registration State\", \"Vehicle Make\", \"Street Name\"]\n",
    "(len(df) - len(df.drop_nulls(subset=subset))) * 100\n",
    "\n",
    "subset = [\"Plate ID\", \"Registration State\", \"Street Name\"]\n",
    "(len(df) - len(df.drop_nulls(subset=subset))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 ms ± 11.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# How many rows would you eliminate if you required at least three non-null \n",
    "# values from the four columns Plate ID, Registration State, Vehicle Make, and\n",
    "# Street Name\n",
    "\n",
    "rows_with_at_least_3_non_nans = len(\n",
    "    df.filter(\n",
    "        (\n",
    "            df['Plate ID'].is_not_null().cast(int) + \n",
    "            df['Registration State'].is_not_null().cast(int) + \n",
    "            df['Vehicle Make'].is_not_null().cast(int) + \n",
    "            df['Street Name'].is_not_null().cast(int)\n",
    "        ) >= 3)\n",
    ")\n",
    "len(df) - rows_with_at_least_3_non_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846 ns ± 9.27 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Which of the columns you've imported has the greatest number of NaN values\n",
    "df.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.6 ms ± 87.9 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Null data is bad, but there is plenty of bad non-null data, too. For example,\n",
    "# many cars with BLANKPLATE as a plate ID were ticketed. Turn these into NaN \n",
    "# values, and rerun the previous query.\n",
    "\n",
    "(\n",
    "    df\n",
    "    .with_columns(df['Plate ID'].replace('BLANKPLATE', None).alias('Plate ID'))\n",
    "    .null_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The goal of this exercise is to find the average age of celebrities who died February–July 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"data/celebrity_deaths_2016.csv\"\n",
    "df = pd.read_csv(path, usecols=[\"dateofdeath\", \"age\"], parse_dates=[\"dateofdeath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.51 ms ± 24.7 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# add new column with month\n",
    "df[\"month\"] = df[\"dateofdeath\"].map(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change index to month\n",
    "df.reset_index(inplace=True)\n",
    "df = df.set_index(keys=['month'], drop=True).drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort df by index\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.28 ms, sys: 1.12 ms, total: 10.4 ms\n",
      "Wall time: 9.91 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# clean all nonintegers in age column\n",
    "df[\"age\"] = df[\"age\"].replace(r\"[a-zA-Z/ ._-]*\", \"\", regex=True).str.slice(0, 2)\n",
    "\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], errors='coerce')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.9 μs ± 562 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# age to int\n",
    "df[\"age\"] = df[\"age\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.7 μs ± 156 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# find avg age from feb to july\n",
    "df.loc[2:7, \"age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 μs ± 2.03 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "import datetime as dt\n",
    "# mean age value in period [2016-02-15, 2016-07-15]\n",
    "df.reset_index(inplace=True, drop=False)\n",
    "df.set_index(keys=[\"dateofdeath\"], drop=True, inplace=True)\n",
    "\n",
    "start = df.index.searchsorted(dt.datetime(2016, 2, 15))\n",
    "end = df.index.searchsorted(dt.datetime(2016, 7, 15))\n",
    "df[start:end]['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.21 ms ± 91 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#top 5 cause of death\n",
    "df = pd.read_csv(path, usecols=[\"dateofdeath\", \"age\", \"causeofdeath\"], parse_dates=[\"dateofdeath\"])\n",
    "df[\"causeofdeath\"].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444 μs ± 7.47 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#top 5 cause of death with unknown\n",
    "df[\"causeofdeath\"].replace(pd.NA, \"unknown\").value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/celebrity_deaths_2016.csv\"\n",
    "df = pl.read_csv(\n",
    "    path, columns=[\"dateofdeath\", \"age\"], \n",
    "    try_parse_dates=True, \n",
    "    ignore_errors=True, \n",
    "    schema=pl.Schema(\n",
    "        {\n",
    "            \"dateofdeath\": pl.Date,\n",
    "            \"name\": pl.String, \n",
    "            \"age\": pl.String,\n",
    "            \"bio\": pl.String,\n",
    "            \"causeofdeath\": pl.String\n",
    "        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.59 ms, sys: 2.33 ms, total: 3.92 ms\n",
      "Wall time: 950 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# add new column with month\n",
    "df = df.with_columns(pl.col(\"dateofdeath\").dt.month().alias(\"month\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 μs ± 1.35 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# sort by month\n",
    "df.sort(by=[\"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.17 ms, sys: 25.4 ms, total: 29.6 ms\n",
      "Wall time: 23.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# clean all nonintegers in age column\n",
    "df = (\n",
    "        df\n",
    "        .with_columns(pl.col(\"age\").replace(r\"^[0-9]*\", None).str.slice(0,2)\n",
    "                      .cast(int, wrap_numerical=True)).drop_nulls()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395 μs ± 8.12 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# find avg age from feb to july\n",
    "df.filter((pl.col(\"month\")>=2) & (pl.col(\"month\") <= 7)).select(\"age\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423 μs ± 6.14 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "import datetime as dt\n",
    "# mean age value in period [2016-02-15, 2016-07-15]\n",
    "start = dt.datetime(2016, 2, 15)\n",
    "end = dt.datetime(2016, 7, 15)\n",
    "df.filter((pl.col(\"dateofdeath\")>=start) & (pl.col(\"dateofdeath\") <= end)).select(\"age\").mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564 μs ± 38.9 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#top 5 cause of death\n",
    "df = pl.read_csv(path, columns=[\"causeofdeath\"])\n",
    "df[\"causeofdeath\"].drop_nulls().value_counts(sort=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 μs ± 2.71 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#top 5 cause of death with unknown\n",
    "df[\"causeofdeath\"].fill_null(\"unknown\").value_counts(sort=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fill in missing data from the famous Titanic data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/titanic3.xls\"\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "# df.to_csv('data/titanic3.csv', index=False) # for arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214 μs ± 2.01 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# which columns contain null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# For each column containing null values, decide whether you will fill it with a\n",
    "# value—and if so, with what value, calculated or otherwise\n",
    "df[\"age\"] = df[\"age\"].interpolate()\n",
    "df[df[\"fare\"].isna()]  = df[df[\"fare\"] < 400]['fare'].mean().astype(int)\n",
    "df = df.dropna(subset=[\"embarked\"])\n",
    "df[\"home.dest\"] = df[\"home.dest\"].fillna(df[\"home.dest\"].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4 ms ± 28.6 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Create a series (most_common_destinations) in which the index contains the\n",
    "# unique values from the embarked column and the values are the most common\n",
    "# destination for each value of embarked.\n",
    "\n",
    "most_common_destinations = pd.Series()\n",
    "\n",
    "for name in df['embarked'].dropna().unique():\n",
    "    most_common_destinations.loc[name] = \\\n",
    "        df[df['embarked']==name]['home.dest'].value_counts().index[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.4 μs ± 915 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Replace NaN values in the home.dest column with values from embarked\n",
    "df['home.dest'] = df['home.dest'].fillna(df['embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169 μs ± 1.94 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Use the most_common_destinations series to replace values in home.dest with\n",
    "# the most common values for each embarkation point\n",
    "df['home.dest'] = df['home.dest'].replace(most_common_destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_excel(\"data/titanic3.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.06 ms, sys: 10.8 ms, total: 15.9 ms\n",
      "Wall time: 2.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a series (most_common_destinations) in which the index contains the\n",
    "# unique values from the embarked column and the values are the most common\n",
    "# destination for each value of embarked.\n",
    "d1 = df.group_by(\"embarked\", \"home.dest\").len().drop_nulls()\n",
    "d2 = d1.select(pl.col(\"embarked\"), pl.col(\"len\")).group_by(\"embarked\").max()\n",
    "most_common_destinations = d1.join(d2, on=[\"len\", \"embarked\"]).select(\"embarked\", \"home.dest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.44 ms, sys: 2.1 ms, total: 3.54 ms\n",
      "Wall time: 887 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Replace NaN values in the home.dest column with values from embarked\n",
    "df = df.with_columns(pl.col(\"home.dest\").fill_null(pl.col(\"embarked\")).alias(\"home.dest\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352 μs ± 9.96 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Use the most_common_destinations series to replace values in home.dest with\n",
    "# the most common values for each embarkation point\n",
    "(\n",
    "    df\n",
    "    .join(most_common_destinations, \n",
    "          left_on=\"home.dest\", right_on=\"embarked\", how=\"left\")\n",
    "    .with_columns(\n",
    "        pl.col(\"home.dest_right\").fill_null(pl.col(\"home.dest\"))\n",
    "        .alias(\"home.dest\")\n",
    "    )\n",
    "    .drop([\"home.dest_right\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Inconsistent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/nyc-parking-violations-2020.csv', \n",
    "                 usecols=[\"Plate ID\", \"Registration State\", \"Vehicle Make\", \n",
    "                          \"Vehicle Color\", \"Street Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217 ms ± 2.18 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# distinct vehicle colors\n",
    "len(df[\"Vehicle Color\"].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371 ms ± 1.67 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# top 30 colors\n",
    "df[\"Vehicle Color\"].value_counts()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary\n",
    "colormap = {'WH': 'WHITE', 'GY':'GRAY',\n",
    "'BK':'BLACK', 'BL':'BLUE',\n",
    "'RD':'RED', 'GR':'GRAY',\n",
    "'TN':'TAN', 'BR':'BROWN',\n",
    "'YW':'YELLO', 'BLK':'BLACK',\n",
    "'GRY':'GRAY', 'WHT':'WHITE',\n",
    "'WHI':'WHITE', 'OR':'ORANG',\n",
    "'BK.':'BLACK', 'WT':'WHITE',\n",
    "'WT.':'WHITE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.53 s ± 52.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Replace the existing (old) colors with your translations. How many colors are\n",
    "# there now\n",
    "df[\"Vehicle Color\"] = df[\"Vehicle Color\"].replace(colormap)\n",
    "len(df[\"Vehicle Color\"].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.93 s ± 45 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Run value_counts on the Vehicle Make column, and look at some vehicle\n",
    "# names. Write a function that, given a value, cleans up the data: putting \n",
    "# the name in all caps, removing punctuation, and standardizing whatever names \n",
    "# you can. Then use the apply method to fix the column. How many distinct \n",
    "# vehicle makes are there when you’re done?\n",
    "df['Vehicle Make'].value_counts()[:30]\n",
    "# print(len(df[\"Vehicle Make\"].drop_duplicates()))\n",
    "\n",
    "# simple udf\n",
    "import re\n",
    "def clean(value: str) -> str:\n",
    "    if not isinstance(value, str):\n",
    "        return None\n",
    "    return re.sub(r'[^\\w\\s]','', str(value).upper())\n",
    "\n",
    "df['Vehicle Make'] = df['Vehicle Make'].apply(clean)\n",
    "\n",
    "# print(len(df[\"Vehicle Make\"].dropna().drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('data/nyc-parking-violations-2020.csv', \n",
    "                 columns=[\"Plate ID\", \"Registration State\", \"Vehicle Make\", \n",
    "                          \"Vehicle Color\", \"Street Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 ms ± 937 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# distinct vehicle colors\n",
    "df[\"Vehicle Color\"].n_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222 ms ± 4.58 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# top 30 colors\n",
    "df[\"Vehicle Color\"].value_counts(sort=True)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary\n",
    "colormap = {'WH': 'WHITE', 'GY':'GRAY',\n",
    "'BK':'BLACK', 'BL':'BLUE',\n",
    "'RD':'RED', 'GR':'GRAY',\n",
    "'TN':'TAN', 'BR':'BROWN',\n",
    "'YW':'YELLO', 'BLK':'BLACK',\n",
    "'GRY':'GRAY', 'WHT':'WHITE',\n",
    "'WHI':'WHITE', 'OR':'ORANG',\n",
    "'BK.':'BLACK', 'WT':'WHITE',\n",
    "'WT.':'WHITE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14 s ± 51.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Replace the existing (old) colors with your translations. How many colors are\n",
    "# there now\n",
    "(\n",
    "    df\n",
    "    .with_columns(\n",
    "        pl.col(\"Vehicle Color\").replace(colormap).alias(\"Vehicle Color\"))\n",
    "    .n_unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.77 s ± 35.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Run value_counts on the Vehicle Make column, and look at some vehicle\n",
    "# names. Write a function that, given a value, cleans up the data: putting \n",
    "# the name in all caps, removing punctuation, and standardizing whatever names \n",
    "# you can. Then use the apply method to fix the column. How many distinct \n",
    "# vehicle makes are there when you’re done?\n",
    "df['Vehicle Make'].value_counts(sort=True)[:30]\n",
    "# print(df[\"Vehicle Make\"].n_unique())\n",
    "\n",
    "# simple udf\n",
    "import re\n",
    "def clean(value: str) -> str:\n",
    "    if not isinstance(value, str):\n",
    "        return None\n",
    "    return re.sub(r'[^\\w\\s]','', str(value).upper())\n",
    "\n",
    "(\n",
    "    df\n",
    "    .with_columns(pl.col('Vehicle Make')\n",
    "                  .map_elements(clean, return_dtype=pl.String)\n",
    "                  .alias('Vehicle Make'))\n",
    "    .select(\"Vehicle Make\")\n",
    "    .drop_nulls()\n",
    "    .n_unique()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
